{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7960b765-6395-44e1-9013-45b82f4df554",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a00b0f0-5dbb-404e-a644-ae532e611f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import randint\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.init import xavier_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f6f87-9d2d-45c4-a58e-6f9098039dfb",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1249015-10c5-4821-8ba6-727c801cf72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- model config -----\n",
    "dataset_dir = \"./dataset_with_deepcrack\"\n",
    "labels = [\"crack\"]\n",
    "weight_regularizer = None\n",
    "image_shape = (224, 224, 3)\n",
    "noise_dim = (224,224,3)\n",
    "SIZE=image_shape[0]\n",
    "\n",
    "ch = 64                                         # default filter depth for the conv blocks\n",
    "n_dis = 6                                      # number of covolution in the block of discriminator\n",
    "c_dim = len(labels) + 1                         # number of domains for image translation, crack, water_seepage,     normal \n",
    "n_res = 6                                       # number of res_block in bottleneck of image-to-image module\n",
    "\n",
    "# ----- training config -----\n",
    "buffer_size = 1000\n",
    "batch_size=1\n",
    "\n",
    "lr = 1e-4\n",
    "n_disc_iteration = 1                            # critic iteration before update of generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7059c-20e5-4151-9d44-03fc46b6441b",
   "metadata": {},
   "source": [
    "# Load DCT Dictionary and Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f6060b7-952d-412a-aa8f-8f075f8151f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = tf.convert_to_tensor(np.load(\"./DCT_U.npy\"))\n",
    "U_T = tf.convert_to_tensor(np.load(\"./DCT_U_T.npy\"))\n",
    "energy_mask = tf.convert_to_tensor(np.load(\"./DCT_mask.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e04249f-cd26-4d81-8a9b-2d7dab54213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT_U_ = tf.cast(U, tf.float32)[tf.newaxis, ...,tf.newaxis]\n",
    "DCT_U  = tf.concat([DCT_U_] * 9408, axis=0)\n",
    "DCT_U_T_ = tf.cast(U_T, dtype=tf.float32)[tf.newaxis,...,tf.newaxis]\n",
    "DCT_U_T = tf.concat([DCT_U_T_] * 9408,  axis=0)\n",
    "\n",
    "DCT_freq_domain_mask_ = tf.cast(energy_mask, dtype=tf.float32)[tf.newaxis,..., tf.newaxis]\n",
    "DCT_freq_domain_mask = tf.concat([DCT_freq_domain_mask_] * 9408,  axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da220a4-2b1a-4dcd-9ada-9feec60e79f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 8), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCT_freq_domain_mask[0, 0:8, 0:8, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cc451-2d60-45d6-b575-8d7c1ba1571c",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078107ae-ec7c-48c3-9ad4-3d3669f83458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=0, padding_mode='zeros', bias=True): \n",
    "    super().__init__()   \n",
    "    \n",
    "    self.conv = nn.Conv2D(in_channels, out_channels, kernel_size, stride, padding, padding_mode, bias=True)\n",
    "    \n",
    "  def forward(self, x_in):\n",
    "    x = self.conv(x_in)\n",
    "    return x\n",
    "  \n",
    "# def conv(x_init, filters, kernel_size=4, strides=2, pad=0, pad_type='zero', use_bias=True, sn=False):\n",
    "#   x = ZeroPadding2D(padding=(pad, pad))(x_init)\n",
    "#   if sn:\n",
    "#     w = tf.compat.v1.get_variable(\"kernel\", shape=[kernel_size, kernel_size, x.get_shape()[-1], channels], initializer=weight_init,\n",
    "#                         regularizer=weight_regularizer)\n",
    "#     x = Conv2D(input=x, filter=spectral_norm(w),\n",
    "#                strides=[1, strides, strides, 1], padding='VALID')\n",
    "#     if use_bias:\n",
    "#         bias = tf.get_variable(\"bias\", [filters], initializer=tf.constant_initializer(0.0))\n",
    "#         x = tf.nn.bias_add(x, bias)\n",
    "\n",
    "#   else:\n",
    "#     x = Conv2D(filters, kernel_size=(kernel_size,kernel_size), kernel_initializer=weight_init, kernel_regularizer=weight_regularizer, strides=(strides,strides), use_bias=use_bias)(x)\n",
    "#   return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bff4d25-74e2-42d0-b60f-f7ac90b37bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deconv(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, bias=True):\n",
    "    super().__init__()\n",
    "    self.conv_t = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, bias)\n",
    "    \n",
    "  def forward(self, x_in):\n",
    "    return self.conv_t(x_in)\n",
    "\n",
    "# def deconv(x, filters, kernel_size=4, strides=2, use_bias=True):\n",
    "#   x = Conv2DTranspose(filters=filters, \n",
    "#                       kernel_size=kernel_size, \n",
    "#                       kernel_initializer=weight_init, \n",
    "#                       kernel_regularizer=weight_regularizer,\n",
    "#                       strides=strides, \n",
    "#                       padding='same', \n",
    "#                       use_bias=use_bias)(x)\n",
    "#   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db774d-0f1b-45c9-8309-c7068824acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    channel = ch\n",
    "    self.disc = nn.Sequential(\n",
    "      conv(3, channel, kernel_size=4, stride=2, padding=1, bias=True),\n",
    "      nn.LeakyReLU(0.01),\n",
    "      *[nn.Sequential(\n",
    "          conv(channel*(2**(i-1)), channel * (2**i), kernel_size=4, strides=2, pad=1, use_bias=True),\n",
    "          nn.LeakyReLU(0.01)\n",
    "        ) \n",
    "        for i in range(1, n_dis)\n",
    "       ],\n",
    "      \n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "def discriminator():\n",
    "  channel = ch\n",
    "  input = Input(shape=(image_shape))\n",
    "  x = conv(input, channel, kernel_size=4, strides=2, pad=1, use_bias=True)\n",
    "  x = LeakyReLU(0.01)(x)\n",
    "\n",
    "  for i in range(1, n_dis):\n",
    "    x = conv(x, channel * 2, kernel_size=4, strides=2, pad=1, use_bias=True)\n",
    "    x = LeakyReLU(0.01)(x)\n",
    "\n",
    "    channel = channel * 2\n",
    "\n",
    "  c_kernel = int(image_shape[0] / np.power(2, n_dis))\n",
    "\n",
    "  logit = conv(x, 1, kernel_size=3, strides=1, pad=1, use_bias=False)\n",
    "  c     = conv(x, c_dim, kernel_size=c_kernel, strides=1, use_bias=False)\n",
    "  \n",
    "  c = tf.reshape(c, shape=[-1, c_dim])\n",
    "  c = Dense(c_dim, activation=\"softmax\")(c)\n",
    "  \n",
    "  model = Model(input, [logit, c])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70e9b7-462f-4ae7-a97a-3afea874082d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "disc = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d882d95-7918-4304-a584-337d4676b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal((1,)+image_shape, 0, 1)\n",
    "print(disc(x)[0].shape)\n",
    "print(disc(x)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06c83c-ad63-45e4-b356-a1df49114575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(x_in, filters, use_bias=True, scope='resblock'):\n",
    "  input = x_in\n",
    "  x = conv(input, filters, kernel_size=3, strides=1, pad=1, use_bias=use_bias)\n",
    "  x = InstanceNormalization()(x)\n",
    "  x = ReLU()(x)\n",
    "  x = conv(x, filters, kernel_size=3, strides=1, pad=1, use_bias=use_bias)\n",
    "  x = InstanceNormalization()(x)\n",
    "  return x + input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8be98-9a69-408a-a50e-8bab495d129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample(x, scale_factor_h, scale_factor_w):\n",
    "  _, h, w, _ = x.get_shape().as_list()\n",
    "  new_size = [h // scale_factor_h, w // scale_factor_w]\n",
    "  return tf.image.resize(x, new_size, method='nearest')\n",
    "\n",
    "def param_free_norm(x, epsilon=1e-5):\n",
    "  x_mean, x_var = tf.nn.moments(x, axes=[1, 2])\n",
    "  x_std = tf.sqrt(x_var + epsilon)\n",
    "  return (x - x_mean) / x_std\n",
    "\n",
    "def spade(segmap, x_init, filters=None, use_bias=True, sn=False) :\n",
    "  x = param_free_norm(x_init)\n",
    "\n",
    "  _, x_h, x_w, n_filters = x_init.get_shape().as_list()\n",
    "  _, segmap_h, segmap_w, _ = segmap.get_shape().as_list()\n",
    "  \n",
    "  factor_h = segmap_h // x_h  # 256 // 4 = 64\n",
    "  factor_w = segmap_w // x_w\n",
    "\n",
    "  segmap_down = down_sample(segmap, factor_h, factor_w)\n",
    "\n",
    "  segmap_down = conv(segmap_down, filters=128, kernel_size=5, strides=1, pad=2, use_bias=use_bias, sn=sn)\n",
    "  segmap_down = ReLU()(segmap_down)\n",
    "\n",
    "  segmap_gamma = conv(segmap_down, filters=filters, kernel_size=5, strides=1, pad=2, use_bias=use_bias, sn=sn)\n",
    "  segmap_beta = conv(segmap_down, filters=filters, kernel_size=5, strides=1, pad=2, use_bias=use_bias, sn=sn)\n",
    "\n",
    "  x = x * (1 + segmap_gamma) + segmap_beta\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe730f04-849b-4ed7-8e36-31504b7606e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spade_resblock(segmap, x_init, filters, use_bias=True, sn=False):\n",
    "  channel_in = x_init.get_shape().as_list()[-1]\n",
    "  channel_middle = min(channel_in, filters)\n",
    "\n",
    "  x = spade(segmap, x_init, channel_in, use_bias=use_bias, sn=False)\n",
    "  x = LeakyReLU(0.2)(x)\n",
    "  x = conv(x, filters=channel_middle, kernel_size=3, strides=1, \n",
    "           pad=1, use_bias=use_bias, sn=sn)\n",
    "  x = spade(segmap, x, filters=channel_middle, use_bias=use_bias, \n",
    "            sn=False)\n",
    "  x = LeakyReLU(0.2)(x)\n",
    "  x = conv(x, filters=filters, kernel_size=3, strides=1, pad=1, \n",
    "           use_bias=use_bias, sn=sn)\n",
    "\n",
    "  if channel_in != filters:\n",
    "    x_init = spade(segmap, x_init, filters=channel_in, use_bias=use_bias, sn=False)\n",
    "    x_init = conv(x_init, filters=filters, kernel_size=1, strides=1, \n",
    "                  use_bias=False, sn=sn)\n",
    "  return x + x_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76400e88-ae3c-487b-9842-608615885394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adative_noise_multiplier(z):\n",
    "  x = Conv2D(32, (5,5), 2, padding=\"same\")(z)\n",
    "  x = ReLU()(x)\n",
    "  x = Conv2D(64, (3,3), 2, padding=\"same\")(x)\n",
    "  x = ReLU()(x)\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(128, activation=\"relu\")(x)\n",
    "  x = Dense(1, activation=\"sigmoid\")(x)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d2f0b-6601-4dd0-b653-1b497ace5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    channel = ch\n",
    "    x_in = Input(shape=image_shape)\n",
    "    c_in = Input(shape=(image_shape[0], image_shape[1], c_dim))\n",
    "    \n",
    "    z = Input(shape=noise_dim)\n",
    "    \n",
    "    lambda_z = adative_noise_multiplier(z)\n",
    "    x = tf.concat([x_in, lambda_z * z], axis=-1)\n",
    "    # in the past, c_in is of shape (c_dim,), now c_in has also the spacial information, therefore no need to tf.tile(c_in, [1, x_in.shape[1], x_in.shape[2], 1])   \n",
    "    x = conv(x, channel, kernel_size=7, strides=1, pad=3, use_bias=False)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "\n",
    "    # Down-Sampling\n",
    "    for i in range(3):\n",
    "      x = conv(x, channel*2, kernel_size=4, strides=2, pad=1, use_bias=False)\n",
    "      x = InstanceNormalization()(x)\n",
    "      x = ReLU()(x)\n",
    "\n",
    "      channel = channel * 2\n",
    "\n",
    "    # Bottleneck\n",
    "    for i in range(n_res):\n",
    "      x = res_block(x, channel, use_bias=False)\n",
    "\n",
    "    # Up-Sampling\n",
    "    for i in range(3):\n",
    "      # need to feed the spatial control map here\n",
    "      x = deconv(x, channel//2, kernel_size=4, strides=2, use_bias=False)\n",
    "      # spade normalization instead\n",
    "      x = spade_resblock(c_in, x, channel//2)\n",
    "      x = ReLU()(x)\n",
    "\n",
    "      channel = channel // 2\n",
    "    \n",
    "    \n",
    "    pre_mask = conv(x, filters=1, kernel_size=7, strides=1, pad=3, use_bias=False)\n",
    "    mask = Activation(\"sigmoid\")(pre_mask)\n",
    "    \n",
    "    x = deconv(x, channel//2, kernel_size=4, strides=2, use_bias=False)\n",
    "    x = spade_resblock(tf.image.resize(c_in, (448,448), method='nearest'), x, channel//2)\n",
    "    x = ReLU()(x)\n",
    "        \n",
    "    defect_overlay = conv(x, filters=3, kernel_size=7, strides=1, pad=3, use_bias=False)\n",
    "    defect_overlay = tf.reshape(defect_overlay, (9408, 8, 8, 1))\n",
    "    defect_overlay = tf.einsum(\"oik...,okj...->oij...\", tf.einsum(\"oikb,okjb->oijb\", DCT_U_T, defect_overlay), DCT_U)\n",
    "    defect_overlay = tf.einsum(\"oij...,oij...->oij...\", DCT_freq_domain_mask, defect_overlay)           # reduce the learning parameter\n",
    "    defect_overlay = tf.einsum(\"oik...,okj...->oij...\", tf.einsum(\"oik...,okj...->oij...\", DCT_U, defect_overlay), DCT_U_T)\n",
    "    defect_overlay = tf.reshape(defect_overlay, (448,448,3))\n",
    "    defect_overlay = tf.image.resize(defect_overlay, (224,224), method='nearest')\n",
    "    defect_overlay = Activation(\"tanh\")(defect_overlay)\n",
    "    model = Model([x_in, c_in, z], [defect_overlay, mask])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec2580-351c-48f6-a7ea-fb4fddf3e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator()\n",
    "# gen.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ebd232-1359-4c64-80cb-095162dc903e",
   "metadata": {},
   "source": [
    "# Dataset Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415824f7-fb26-40ab-89d2-4dcb2b523f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043de96a-4946-4847-b93c-09e9f4214464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(index, length):\n",
    "  zeros = np.zeros((length, ))\n",
    "  zeros[index] = 1\n",
    "  return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaddb0c-1be5-42a0-b9c2-dd301494cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_and_spatialCatMap_and_defectOneHot_and_normalOnehot(segment_filepath, index):  \n",
    "  # only EagerTensor can be decoded as follows:\n",
    "  index = int(bytes.decode(index))\n",
    "  segment_filepath = bytes.decode(segment_filepath)\n",
    "  segment = img_to_array(load_img(segment_filepath, target_size=(SIZE,SIZE), color_mode=\"grayscale\"))\n",
    "  segment = np.where(segment>0.5, 1, 0)\n",
    "  \n",
    "  spatial_cat_map = np.zeros((SIZE, SIZE, c_dim))\n",
    "  \n",
    "  # create spatial_categorical map from segmentation and index of the defect class\n",
    "  \n",
    "  for x in range(SIZE):\n",
    "    for y in range(SIZE):\n",
    "      if segment[x,y,0] > 0:\n",
    "        spatial_cat_map[x,y,index] = 1\n",
    "  \n",
    "  defect_onehot = one_hot(index, c_dim)\n",
    "  normal_onehot = one_hot(c_dim-1, c_dim) # onehot with last entry as 1, else 0\n",
    "      \n",
    "  return tf.convert_to_tensor(segment, dtype=tf.float32), \\\n",
    "          tf.convert_to_tensor(spatial_cat_map, dtype=tf.float32), \\\n",
    "          tf.convert_to_tensor(defect_onehot, dtype=tf.float32),\\\n",
    "          tf.convert_to_tensor(normal_onehot, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c126f-9dc2-4823-b81c-b7e621e0d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def path_to_img(zipped_filepaths):\n",
    "  normal_filepath = zipped_filepaths[0]\n",
    "  defect_filepath = zipped_filepaths[1]\n",
    "  segment_filepath = zipped_filepaths[2]\n",
    "  defect_index = zipped_filepaths[3]\n",
    "  \n",
    "  normal = tf.io.read_file(normal_filepath)\n",
    "  normal = tf.image.decode_png(normal, channels=3)\n",
    "  normal = tf.image.resize(normal, (SIZE, SIZE))\n",
    "  normal = (normal/127.5) - 1\n",
    "  \n",
    "  \n",
    "  defect = tf.io.read_file(defect_filepath)\n",
    "  defect = tf.image.decode_png(defect, channels=3)\n",
    "  defect = tf.image.resize(defect, (SIZE, SIZE))\n",
    "  defect = (defect/127.5) - 1\n",
    "  \n",
    "  \n",
    "  segment, spatial_cat_map, defect_onehot, normal_onehot = tf.numpy_function(\n",
    "                                                 func=get_segment_and_spatialCatMap_and_defectOneHot_and_normalOnehot, \n",
    "                                                 inp=[segment_filepath, defect_index], \n",
    "                                                 Tout = [tf.float32, tf.float32, tf.float32, tf.float32]\n",
    "                                                )\n",
    "      \n",
    "  return (normal, defect, segment, defect_index, spatial_cat_map, defect_onehot, normal_onehot)\n",
    "\n",
    "def get_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen(random_segmentations=False):\n",
    "  normals = []\n",
    "  defects = []\n",
    "  defect_segmentations = []\n",
    "  defect_indexes = []\n",
    "\n",
    "  for label in labels:\n",
    "    index = labels.index(label)\n",
    "    normals += glob.glob(f\"{dataset_dir}/{label}/normal/*.jpg\")\n",
    "    defects += glob.glob(f\"{dataset_dir}/{label}/defect/*.jpg\")\n",
    "    defect_segmentations += glob.glob(f\"{dataset_dir}/{label}/defect_segmentation/*.png\")\n",
    "    \n",
    "    if random_segmentations:\n",
    "      random.shuffle(defect_segmentations)\n",
    "      \n",
    "    defect_indexes += [str(index)] * len(normals) # normals, defects, defect_segementations are all of the same length, just use one of them\n",
    "    \n",
    "  normal_defect_defectSeg = list(zip(normals, defects, defect_segmentations, defect_indexes))\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(normal_defect_defectSeg)\\\n",
    "              .map(path_to_img)\\\n",
    "              .batch(batch_size)\\\n",
    "              .shuffle(buffer_size)\\\n",
    "              .cache()\n",
    "\n",
    "  return iter(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd80bf-fd6f-49d5-acdc-da4739f3f701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def view_dataset_sample():\n",
    "  normals, defects, segments, indexes, spatial_cat_maps, _, _ = next(get_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen())\n",
    "  #   spatial_cat_map_[:,:,index] = segments\n",
    "  for i in range(0, 1):\n",
    "    normal = normals[i].numpy().astype(\"float32\")\n",
    "    defect = defects[i].numpy().astype(\"float32\")\n",
    "    segment = segments[i].numpy().astype(\"float32\")\n",
    "    spatial_cat_map = spatial_cat_maps[i]\n",
    "    index = int(indexes[i])\n",
    "    label = labels[index]\n",
    "    \n",
    "    print(\"label\", label)\n",
    "    plt.figure(figsize=(6, 15))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(((normal+1)*127.5).astype(\"uint8\"))\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(((defect+1)*127.5).astype(\"uint8\"))\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(spatial_cat_map[:,:,index])\n",
    "    \n",
    "view_dataset_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe580c-419d-42e0-85d9-535ba44020a1",
   "metadata": {},
   "source": [
    "# Train Loop with Helper Function to see Intermediate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f8489-5c38-4c8f-bb10-db93b8c1ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = MeanAbsoluteError()\n",
    "cce = CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e5b18-462f-4e5d-8bba-40a23fa7aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator()\n",
    "disc = discriminator()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e8707-77c5-4ab5-b7f4-0a41fc614b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def view_generator_sample(image_name=None, show_in_notebook=True):\n",
    "  datagen = get_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen()\n",
    "  dategen_randomSeg = get_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen(random_segmentations=True)\n",
    "\n",
    "  normals, defects, segments, indexes, spatial_cat_maps, _, _ = next(datagen)\n",
    "  normals_, defects_, segments_, indexes_, spatial_cat_maps_, _, _ = next(dategen_randomSeg)\n",
    "  #   spatial_cat_map_[:,:,index] = segments\n",
    "  \n",
    "  if image_name is not None:\n",
    "    print(\"\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"---------\")\n",
    "    print(image_name)\n",
    "  \n",
    "  plt.figure(figsize=(17, 10))\n",
    "  \n",
    "  for i in range(0, 1):\n",
    "    spatial_cat_map_randomSeg = spatial_cat_maps_[i]\n",
    "    \n",
    "    spatial_cat_map = spatial_cat_maps[i]\n",
    "    normal = normals[i].numpy().astype(\"float32\")\n",
    "    \n",
    "    defect = defects[i].numpy().astype(\"float32\")\n",
    "    \n",
    "    for row_count, (from_, spa_cat, description) in enumerate([\n",
    "      (defect, spatial_cat_map, \"from_defect\"), \n",
    "      (normal, spatial_cat_map, \"from_normal\"), \n",
    "      (normal, spatial_cat_map_randomSeg, \"from_random_segment\")\n",
    "    ]):\n",
    "      segment = segments[i].numpy().astype(\"float32\")\n",
    "      z = np.random.normal(0, 1, (1, )+noise_dim)\n",
    "\n",
    "      top, m = gen.predict([from_[np.newaxis,...], spa_cat[np.newaxis,...], z])\n",
    "      print(top.shape)\n",
    "      top_layer = np.squeeze(top)\n",
    "\n",
    "\n",
    "      index = int(indexes[i])\n",
    "      label = labels[index]\n",
    "\n",
    "\n",
    "\n",
    "      plt.subplot(3, 5, 5*row_count + 1)\n",
    "      plt.imshow(((from_+1)*127.5).astype(\"uint8\"))\n",
    "\n",
    "      plt.subplot(3, 5, 5*row_count + 2)\n",
    "      plt.imshow(spa_cat[:,:,index])\n",
    "\n",
    "\n",
    "      plt.subplot(3, 5, 5*row_count + 3)\n",
    "\n",
    "      plt.imshow(((top_layer+1)*127.5).astype(\"uint8\"))\n",
    "\n",
    "      plt.subplot(3, 5, 5*row_count + 4)\n",
    "      print(\"max mask value inside mask:\", np.amax(m))\n",
    "      plt.imshow(np.squeeze(m))\n",
    "\n",
    "      plt.subplot(3, 5, 5*row_count + 5)\n",
    "      gened_defects = from_ * (1-m)  + top_layer * m\n",
    "      plt.imshow(((gened_defects[0]+1)*127.5).astype(\"uint8\"))\n",
    "\n",
    "\n",
    "    if image_name is not None:\n",
    "      plt.savefig(f\"{image_name}\", dpi=80, bbox_inches=\"tight\")\n",
    "\n",
    "    if show_in_notebook:\n",
    "      plt.show()\n",
    "  \n",
    "view_generator_sample(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62016b31-da3c-45d2-8e3e-98e4aaa2b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penality(critic, real_sample, fake_sample):\n",
    "    epsilon = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    interpolated = epsilon * real_sample + (1 - epsilon) * fake_sample\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "      gp_tape.watch(interpolated)\n",
    "      critic_inter = critic(interpolated, training=True)\n",
    "\n",
    "    grads = gp_tape.gradient(critic_inter, [interpolated])[0]\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    penality = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return penality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e45293-a8b7-4f2d-8b12-93166994928b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoches=10, sample_per_batch=15, show_in_notebook=True):\n",
    "  \n",
    "  g_opt = Adam(lr=lr, beta_1=0, beta_2=0.9)\n",
    "  d_opt = Adam(lr=lr, beta_1=0, beta_2=0.9)\n",
    "  \n",
    "  \n",
    "  for epoch in range(epoches):\n",
    "    batch = 0\n",
    "    dataset_gen = get_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen()\n",
    "    \n",
    "    if epoch == 0:\n",
    "      lambda_mask = 5.0\n",
    "    elif  epoch >= 1 and epoch <= 2:\n",
    "      lambda_mask = 0.5\n",
    "    else:\n",
    "      lambda_mask = 0\n",
    "    \n",
    "    \n",
    "    for normals, defects, _, _, spatial_cat_maps, defect_onehots, normal_onehots in dataset_gen:\n",
    "      batch += 1\n",
    "      print(\"epoch\", epoch+1, \"batch\", batch, end=\"\\r\")\n",
    "      \n",
    "      for iteration in range(n_disc_iteration):\n",
    "        update_gen = (iteration+1)%n_disc_iteration == 0\n",
    "\n",
    "        for from_, to_, from_onehots, target_onehots in [(normals, defects, normal_onehots, defect_onehots), (defects, normals, defect_onehots, normal_onehots)]:\n",
    "          z_1 = tf.random.normal((1,)+noise_dim, 0, 1)\n",
    "          z_2 = tf.random.normal((1,)+noise_dim, 0, 1)\n",
    "\n",
    "          with tf.GradientTape(persistent=True) as tape:\n",
    "            # naming convetion is from normal --> defect. Roles of normal and defect can be interchanged\n",
    "            defect_overlays, n2d_masks = gen([from_, spatial_cat_maps, z_1], training=True)\n",
    "            gened_defects = from_ * (1-n2d_masks)  + defect_overlays * n2d_masks\n",
    "\n",
    "            restore_overlays, d2n_masks = gen([gened_defects, spatial_cat_maps, z_2], training=True)\n",
    "            restoration = gened_defects * (1-d2n_masks) + restore_overlays * d2n_masks\n",
    "\n",
    "            d_logit_on_gened, d_cls_on_gened = disc(gened_defects, training=True)\n",
    "            d_logit_on_real, d_cls_on_real = disc(from_, training=True)\n",
    "\n",
    "            cls_loss_on_gened = cce(target_onehots, d_cls_on_gened)\n",
    "            cls_loss_on_real = cce(from_onehots, d_cls_on_real)\n",
    "\n",
    "            gp = gradient_penality(disc, from_, gened_defects)\n",
    "\n",
    "            d_wgan_gp_loss = tf.math.reduce_mean(d_logit_on_gened) - tf.reduce_mean(d_logit_on_real) + 10 * gp\n",
    "\n",
    "\n",
    "            g_cycle_loss = mae(from_, restoration)\n",
    "\n",
    "            g_mask_cycle_loss = mae(n2d_masks, d2n_masks)\n",
    "\n",
    "            g_mask_vanishing_loss = -tf.math.log(tf.math.reduce_mean(mae(n2d_masks, 0.0) +  mae(d2n_masks, 0.0))) \n",
    "            g_mask_spatial_constraint_loss = tf.math.reduce_mean(mae(n2d_masks, 0.0) +  mae(d2n_masks, 0.0))\n",
    "\n",
    "            g_wgan_gp_loss = - tf.math.reduce_mean(d_logit_on_gened)\n",
    "\n",
    "            d_loss = tf.tensordot(\n",
    "              [1,              5.0             ],\n",
    "              [d_wgan_gp_loss, cls_loss_on_real],\n",
    "              axes = 1\n",
    "            )\n",
    "\n",
    "            if update_gen:\n",
    "              g_loss = tf.tensordot(\n",
    "                [10.0,         5.0,               lambda_mask,           5.0,                            10.0,              1.0           ],\n",
    "                [g_cycle_loss, g_mask_cycle_loss, g_mask_vanishing_loss, g_mask_spatial_constraint_loss, cls_loss_on_gened, g_wgan_gp_loss],\n",
    "                axes = 1\n",
    "              )\n",
    "              \n",
    "          grad_of_d = tape.gradient(d_loss, disc.trainable_variables)\n",
    "          d_opt.apply_gradients(zip(grad_of_d, disc.trainable_variables))\n",
    "\n",
    "          if update_gen:\n",
    "            grad_of_g = tape.gradient(g_loss, gen.trainable_variables)\n",
    "            g_opt.apply_gradients(zip(grad_of_g, gen.trainable_variables))\n",
    "\n",
    "      \n",
    "      if (batch % sample_per_batch) == 0:\n",
    "        view_generator_sample(\n",
    "          image_name=\"epoch-{}-batch-{}-224-DCT-ver\".format(\n",
    "            str(epoch+1).zfill(3), \n",
    "            str(batch).zfill(5)\n",
    "          ),\n",
    "          show_in_notebook=show_in_notebook\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec128d-f5da-4e80-a27a-f4de94d79c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epoches=8, sample_per_batch=15, show_in_notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac715168-ed50-4337-84ff-14731d2b00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen.save_weights(\"./defect-gan-224ver-DCT-01_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f2a96-dad7-4ec4-9e9d-83e9eded07e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
