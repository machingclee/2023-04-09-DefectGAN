{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7960b765-6395-44e1-9013-45b82f4df554",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a00b0f0-5dbb-404e-a644-ae532e611f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError, CategoricalCrossentropy\n",
    "from tensorflow.keras.initializers import  HeNormal\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv2D, Conv2DTranspose, LeakyReLU, ReLU, Flatten, Dense,\n",
    "  Activation, Concatenate, BatchNormalization, ZeroPadding2D\n",
    ")\n",
    "from glob import glob\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.models import Model\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "from tensorflow_addons.layers import InstanceNormalization, SpectralNormalization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b3efb20-00c7-4dfe-afd1-ffe048e02777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[np.cos(1), -np.sin(1)],\n",
    "        [np.sin(1), np.sin(1)]])\n",
    "a = np.array([[1,2]])\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "522745d1-1531-4979-86f2-e4bfeda31e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.empty(1, dtype=torch.long).random_(5)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc6d080-625c-491a-aff8-05c4e68ff3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15644\\2350412098.py:8: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(\n",
    "  gpu_options=tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01ca8b4e-3752-4077-9c23-9ab5d5fe8028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=3.5>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.9166667>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.moments(tf.convert_to_tensor(np.array([\n",
    "  [1,2],\n",
    "  [3,4],\n",
    "  [5,6]\n",
    "]\n",
    "), dtype=tf.float32), axes=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e170e7b-9bb3-4886-b576-07b845a14bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.tensor(np.array([\n",
    "  [1,2],\n",
    "  [3,4],\n",
    "  [5,6], \n",
    "]).astype(np.float32)), dim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f6f87-9d2d-45c4-a58e-6f9098039dfb",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1249015-10c5-4821-8ba6-727c801cf72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- model config -----\n",
    "dataset_dir = \"./dataset_with_deepcrack\"\n",
    "labels = [\"crack\"]\n",
    "weight_init = initializers.GlorotNormal()\n",
    "weight_regularizer = None\n",
    "image_shape = (224, 224, 3)\n",
    "noise_dim = (224,224,3)\n",
    "SIZE=image_shape[0]\n",
    "\n",
    "ch = 64                                         # default filter depth for the conv blocks\n",
    "n_dis = 6                                      # number of covolution in the block of discriminator\n",
    "c_dim = len(labels) + 1                         # number of domains for image translation, crack, water_seepage,     normal \n",
    "n_res = 6                                       # number of res_block in bottleneck of image-to-image module\n",
    "\n",
    "# ----- training config -----\n",
    "buffer_size = 1000\n",
    "batch_size=1\n",
    "\n",
    "lr = 1e-4\n",
    "n_disc_iteration = 1                            # critic iteration before update of generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7059c-20e5-4151-9d44-03fc46b6441b",
   "metadata": {},
   "source": [
    "# Load DCT Dictionary and Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6060b7-952d-412a-aa8f-8f075f8151f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = tf.convert_to_tensor(np.load(\"./DCT_U.npy\"))\n",
    "U_T = tf.convert_to_tensor(np.load(\"./DCT_U_T.npy\"))\n",
    "energy_mask = tf.convert_to_tensor(np.load(\"./DCT_mask.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e04249f-cd26-4d81-8a9b-2d7dab54213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT_U_ = tf.cast(U, tf.float32)[tf.newaxis, ...,tf.newaxis]\n",
    "DCT_U  = tf.concat([DCT_U_] * 2352, axis=0)\n",
    "DCT_U_T_ = tf.cast(U_T, dtype=tf.float32)[tf.newaxis,...,tf.newaxis]\n",
    "DCT_U_T = tf.concat([DCT_U_T_] * 2352,  axis=0)\n",
    "\n",
    "DCT_freq_domain_mask_ = tf.cast(energy_mask, dtype=tf.float32)[tf.newaxis,..., tf.newaxis]\n",
    "DCT_freq_domain_mask = tf.concat([DCT_freq_domain_mask_] * 2352,  axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4da220a4-2b1a-4dcd-9ada-9feec60e79f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 8), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCT_freq_domain_mask[0, 0:8, 0:8, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cc451-2d60-45d6-b575-8d7c1ba1571c",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "078107ae-ec7c-48c3-9ad4-3d3669f83458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x_init, filters, kernel_size=4, strides=2, pad=0, pad_type='zero', use_bias=True, sn=False):\n",
    "  x = ZeroPadding2D(padding=(pad, pad))(x_init)\n",
    "  if sn:\n",
    "    w = tf.compat.v1.get_variable(\"kernel\", shape=[kernel_size, kernel_size, x.get_shape()[-1], channels], initializer=weight_init,\n",
    "                        regularizer=weight_regularizer)\n",
    "    x = Conv2D(input=x, filter=spectral_norm(w),\n",
    "               strides=[1, strides, strides, 1], padding='VALID')\n",
    "    if use_bias:\n",
    "        bias = tf.get_variable(\"bias\", [filters], initializer=tf.constant_initializer(0.0))\n",
    "        x = tf.nn.bias_add(x, bias)\n",
    "\n",
    "  else:\n",
    "    x = Conv2D(filters, kernel_size=(kernel_size,kernel_size), kernel_initializer=weight_init, kernel_regularizer=weight_regularizer, strides=(strides,strides), use_bias=use_bias)(x)\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24e646a5-e50a-48d6-88d9-5a6bdfe7e8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([1,2]) + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bff4d25-74e2-42d0-b60f-f7ac90b37bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(x, filters, kernel_size=4, strides=2, use_bias=True):\n",
    "  x = Conv2DTranspose(filters=filters, \n",
    "                      kernel_size=kernel_size, \n",
    "                      kernel_initializer=weight_init, \n",
    "                      kernel_regularizer=weight_regularizer,\n",
    "                      strides=strides, \n",
    "                      padding='same', \n",
    "                      use_bias=use_bias)(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8231ab7-4d72-4602-aa4e-172ff598f575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*2**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0db774d-0f1b-45c9-8309-c7068824acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "  channel = ch\n",
    "  input = Input(shape=(image_shape))\n",
    "  x = conv(input, channel, kernel_size=4, strides=2, pad=1, use_bias=True)\n",
    "  x = LeakyReLU(0.01)(x)\n",
    "\n",
    "  print(\"before res\", x.shape)\n",
    "  \n",
    "  for i in range(1, n_dis):\n",
    "    print(\"before\", x.shape)\n",
    "    x = conv(x, channel * 2, kernel_size=4, strides=2, pad=1, use_bias=True)\n",
    "    x = LeakyReLU(0.01)(x)\n",
    "    print(\"after\", x.shape)\n",
    "\n",
    "    channel = channel * 2\n",
    "\n",
    "  c_kernel = int(image_shape[0] / np.power(2, n_dis))\n",
    "\n",
    "  logit = conv(x, 1, kernel_size=3, strides=1, pad=1, use_bias=False)\n",
    "  c     = conv(x, c_dim, kernel_size=c_kernel, strides=1, use_bias=False)\n",
    "  print(\"what is c\", c)\n",
    "  c = tf.reshape(c, shape=[-1, c_dim])\n",
    "  c = Dense(c_dim, activation=\"softmax\")(c)\n",
    "  \n",
    "  model = Model(input, [logit, c])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "601c1b77-821d-4c45-ad85-27c35f4a86eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before res (None, 112, 112, 64)\n",
      "before (None, 112, 112, 64)\n",
      "after (None, 56, 56, 128)\n",
      "before (None, 56, 56, 128)\n",
      "after (None, 28, 28, 256)\n",
      "before (None, 28, 28, 256)\n",
      "after (None, 14, 14, 512)\n",
      "before (None, 14, 14, 512)\n",
      "after (None, 7, 7, 1024)\n",
      "before (None, 7, 7, 1024)\n",
      "after (None, 3, 3, 2048)\n",
      "what is c KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 2), dtype=tf.float32, name=None), name='conv2d_87/Conv2D:0', description=\"created by layer 'conv2d_87'\")\n",
      "[<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
      "array([[[[-0.01486788],\n",
      "         [-0.00109629],\n",
      "         [-0.0169445 ]],\n",
      "\n",
      "        [[ 0.00904904],\n",
      "         [-0.00788207],\n",
      "         [-0.00033179]],\n",
      "\n",
      "        [[ 0.01168608],\n",
      "         [ 0.00461598],\n",
      "         [ 0.00161458]]]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.49640325, 0.5035967 ]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "img = tf.random.normal((1,)+image_shape)\n",
    "print(discriminator()(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c70e9b7-462f-4ae7-a97a-3afea874082d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "disc = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb7a22-b2df-46c6-8111-d12d0338f9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d882d95-7918-4304-a584-337d4676b7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal((1,)+image_shape, 0, 1)\n",
    "print(disc(x)[0].shape)\n",
    "print(disc(x)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d06c83c-ad63-45e4-b356-a1df49114575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(x_in, filters, use_bias=True, scope='resblock'):\n",
    "  input = x_in\n",
    "  x = conv(input, filters, kernel_size=3, strides=1, pad=1, use_bias=use_bias)\n",
    "  x = InstanceNormalization()(x)\n",
    "  x = ReLU()(x)\n",
    "  x = conv(x, filters, kernel_size=3, strides=1, pad=1, use_bias=use_bias)\n",
    "  x = InstanceNormalization()(x)\n",
    "  return x + input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8d8be98-9a69-408a-a50e-8bab495d129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample(x, scale_factor_h, scale_factor_w):\n",
    "  _, h, w, _ = x.get_shape().as_list()\n",
    "  new_size = [h // scale_factor_h, w // scale_factor_w]\n",
    "  return tf.image.resize(x, new_size, method='nearest')\n",
    "\n",
    "def param_free_norm(x, epsilon=1e-5):\n",
    "  x_mean, x_var = tf.nn.moments(x, axes=[1, 2])\n",
    "  x_std = tf.sqrt(x_var + epsilon)\n",
    "  return (x - x_mean) / x_std\n",
    "\n",
    "def spade(segmap, x_init, filters=None, use_bias=True, sn=False) :\n",
    "  x = param_free_norm(x_init)\n",
    "\n",
    "  _, x_h, x_w, n_filters = x_init.get_shape().as_list()\n",
    "  _, segmap_h, segmap_w, _ = segmap.get_shape().as_list()\n",
    "  \n",
    "  factor_h = segmap_h // x_h  # 256 // 4 = 64\n",
    "  factor_w = segmap_w // x_w\n",
    "\n",
    "  segmap_down = down_sample(segmap, factor_h, factor_w)\n",
    "  print(\"segmap_down_before\", segmap_down.shape)\n",
    "  \n",
    "  segmap_down = conv(segmap_down, filters=128, kernel_size=5, strides=1, pad=2, use_bias=use_bias, sn=sn)\n",
    "  segmap_down = ReLU()(segmap_down)\n",
    "  print(\"segmap_down_after\", segmap_down.shape)\n",
    "\n",
    "  segmap_gamma = conv(segmap_down, filters=filters, kernel_size=5, strides=1, pad=2, use_bias=use_bias, sn=sn)\n",
    "  print(segmap_gamma.shape)\n",
    "  segmap_beta = conv(segmap_down, filters=filters, kernel_size=5, strides=1, pad=2, use_bias=use_bias, sn=sn)\n",
    "  print(segmap_beta.shape)\n",
    "\n",
    "  x = x * (1 + segmap_gamma) + segmap_beta\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d6cf34f-5102-47e8-86a7-77ff87e42ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 222, 222, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.random.normal((1,224,224,3))\n",
    "Conv2D(3,3,1)(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "111a2004-ed78-4188-884c-47e524fc2ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmap_down_before (1, 224, 224, 2)\n",
      "segmap_down_after (1, 224, 224, 128)\n",
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=\n",
       "array([[[[-0.47834027, -0.52075297, -0.54263276],\n",
       "         [ 0.1449258 , -0.70773154, -0.53884447],\n",
       "         [ 1.3488685 ,  0.34064212,  0.13908978],\n",
       "         ...,\n",
       "         [ 0.61965257, -0.17014219,  2.6133306 ],\n",
       "         [ 0.29802388,  1.2176508 , -0.6501558 ],\n",
       "         [-1.1606138 ,  0.76208687, -0.24117146]],\n",
       "\n",
       "        [[-0.13942099,  1.061092  , -1.3040532 ],\n",
       "         [-0.59868383, -0.3341473 , -0.2541005 ],\n",
       "         [-0.08816768, -0.12960334,  0.16092728],\n",
       "         ...,\n",
       "         [ 0.78842366, -0.64921933,  0.6197934 ],\n",
       "         [ 1.437762  ,  0.34167823,  0.09363055],\n",
       "         [-1.4757596 ,  0.33890885, -0.15044917]],\n",
       "\n",
       "        [[-0.10350241,  1.5559781 ,  0.8551019 ],\n",
       "         [ 1.7143514 ,  1.4250367 , -2.455861  ],\n",
       "         [-1.000806  ,  0.40142918, -0.11753058],\n",
       "         ...,\n",
       "         [-0.2754567 ,  0.21681476, -0.35205916],\n",
       "         [ 0.52990973, -1.4319388 ,  0.49051952],\n",
       "         [ 0.6814912 , -0.0234538 , -0.41158658]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1199574 ,  0.73250616, -0.05577532],\n",
       "         [-1.0163532 , -0.11618296,  0.9253958 ],\n",
       "         [ 0.9540621 , -0.64587504, -0.21177337],\n",
       "         ...,\n",
       "         [-0.8372063 ,  2.7690654 , -0.18150586],\n",
       "         [-0.5291946 , -1.5391928 , -0.74643123],\n",
       "         [ 0.660547  ,  0.25647736, -0.6984087 ]],\n",
       "\n",
       "        [[-1.5497365 , -0.06980397,  0.13182367],\n",
       "         [ 0.17048934, -0.43216488,  0.23122787],\n",
       "         [ 0.7683892 ,  0.6144989 , -0.062388  ],\n",
       "         ...,\n",
       "         [ 1.3322061 ,  1.957721  ,  0.00887832],\n",
       "         [-1.7152247 ,  0.3044799 ,  0.905439  ],\n",
       "         [ 1.5163662 , -0.08151618, -1.0721122 ]],\n",
       "\n",
       "        [[-0.15847194,  1.6239952 , -0.08921263],\n",
       "         [-0.38473228,  0.5515979 ,  0.71702   ],\n",
       "         [-0.9865468 ,  0.31209582,  0.84159595],\n",
       "         ...,\n",
       "         [-0.35630313, -1.690284  , -1.4541134 ],\n",
       "         [ 0.1492128 ,  0.22548857, -0.15629144],\n",
       "         [-0.04437281, -0.30254254,  0.20398541]]]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = tf.random.normal((1,224,224,2))\n",
    "img = tf.random.normal((1,224,224,3))\n",
    "spade(seg, img, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe730f04-849b-4ed7-8e36-31504b7606e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spade_resblock(segmap, x_init, filters, use_bias=True, sn=False):\n",
    "  channel_in = x_init.get_shape().as_list()[-1]\n",
    "  channel_middle = min(channel_in, filters)\n",
    "\n",
    "  x = spade(segmap, x_init, channel_in, use_bias=use_bias, sn=False)\n",
    "  x = LeakyReLU(0.2)(x)\n",
    "  print(\"before\", x.shape)\n",
    "  x = conv(x, filters=channel_middle, kernel_size=3, strides=1, \n",
    "           pad=1, use_bias=use_bias, sn=sn)\n",
    "  print(\"after\", x.shape)\n",
    "  x = spade(segmap, x, filters=channel_middle, use_bias=use_bias, \n",
    "            sn=False)\n",
    "  x = LeakyReLU(0.2)(x)\n",
    "  x = conv(x, filters=filters, kernel_size=3, strides=1, pad=1, \n",
    "           use_bias=use_bias, sn=sn)\n",
    "\n",
    "  if channel_in != filters:\n",
    "    x_init = spade(segmap, x_init, filters=channel_in, use_bias=use_bias, sn=False)\n",
    "    x_init = conv(x_init, filters=filters, kernel_size=1, strides=1, \n",
    "                  use_bias=False, sn=sn)\n",
    "  return x + x_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4762ba0-9ee0-406a-ab20-c7fcf993430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmap_down_before (1, 224, 224, 2)\n",
      "segmap_down_after (1, 224, 224, 128)\n",
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "before (1, 224, 224, 3)\n",
      "after (1, 224, 224, 3)\n",
      "segmap_down_before (1, 224, 224, 2)\n",
      "segmap_down_after (1, 224, 224, 128)\n",
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=\n",
       "array([[[[-0.16226904,  1.2503673 ,  1.7184045 ],\n",
       "         [ 1.8350139 ,  0.6818882 ,  0.7979938 ],\n",
       "         [-0.2590381 ,  1.7946987 , -1.5179954 ],\n",
       "         ...,\n",
       "         [ 1.4946357 , -1.3769681 , -0.6186542 ],\n",
       "         [-1.3105865 , -0.72273815,  0.05223368],\n",
       "         [ 0.34522146, -0.08216854, -1.0058378 ]],\n",
       "\n",
       "        [[ 1.7431948 , -0.8465154 , -1.2420446 ],\n",
       "         [ 0.24172735, -0.39549077, -0.5744233 ],\n",
       "         [ 1.8759074 , -1.5898281 ,  2.141024  ],\n",
       "         ...,\n",
       "         [-0.45696378, -0.926334  , -0.16208279],\n",
       "         [ 0.11891273, -1.3192569 , -0.13044468],\n",
       "         [-0.59372777, -0.73176694,  0.8767378 ]],\n",
       "\n",
       "        [[ 1.6302989 , -1.5463796 , -0.13776772],\n",
       "         [-0.90783954, -1.0160999 , -0.8009704 ],\n",
       "         [ 0.32501364,  1.3024552 , -1.0070996 ],\n",
       "         ...,\n",
       "         [-0.05200543, -1.8084646 , -2.1630073 ],\n",
       "         [ 0.8470919 , -0.36028892,  0.8720411 ],\n",
       "         [ 3.0931387 , -1.5384743 ,  0.6184871 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.5186063 ,  0.19280738,  0.3298349 ],\n",
       "         [ 0.7486233 ,  1.1616433 , -0.17967528],\n",
       "         [ 2.121552  , -2.0284975 , -0.7516202 ],\n",
       "         ...,\n",
       "         [ 2.304893  , -1.2693408 ,  1.8699309 ],\n",
       "         [ 1.0128962 ,  0.72617483, -1.1940489 ],\n",
       "         [-0.5722989 ,  0.10653061, -1.4082371 ]],\n",
       "\n",
       "        [[ 0.5580539 ,  0.36095425,  0.01893729],\n",
       "         [ 0.7554833 ,  1.6785756 ,  0.25453585],\n",
       "         [ 0.2247445 , -0.18745756,  0.48819727],\n",
       "         ...,\n",
       "         [ 2.403582  ,  2.5020204 , -1.6023715 ],\n",
       "         [ 2.2519224 ,  0.7411623 , -0.06537399],\n",
       "         [-0.00479007,  0.21082255,  0.01612717]],\n",
       "\n",
       "        [[-1.4824078 ,  0.44979718, -1.0125344 ],\n",
       "         [-0.41206247,  0.64539945,  0.42155665],\n",
       "         [-1.9985185 , -0.14418727, -1.0665914 ],\n",
       "         ...,\n",
       "         [-0.1897532 ,  0.27530816,  0.40618718],\n",
       "         [-0.7959074 , -0.01297867,  1.2518675 ],\n",
       "         [-0.8672879 ,  0.11702299, -1.6334369 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = tf.random.normal((1,224,224,2))\n",
    "img = tf.random.normal((1,224,224,3))\n",
    "spade_resblock(seg, img, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76400e88-ae3c-487b-9842-608615885394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.         0.         0.         ... 0.03614397 0.04573695 0.17234616]], shape=(1, 200704), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.45101804]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adative_noise_multiplier(z):\n",
    "  x = Conv2D(32, (5,5), 2, padding=\"same\")(z)\n",
    "  x = ReLU()(x)\n",
    "  x = Conv2D(64, (3,3), 2, padding=\"same\")(x)\n",
    "  x = ReLU()(x)\n",
    "  x = Flatten()(x)\n",
    "  print(x)\n",
    "  x = Dense(128, activation=\"relu\")(x)\n",
    "  x = Dense(1, activation=\"sigmoid\")(x)\n",
    "  \n",
    "  return x\n",
    "\n",
    "noise= tf.random.normal((1,)+noise_dim)\n",
    "adative_noise_multiplier(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca0d2f0b-6601-4dd0-b653-1b497ace5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    channel = ch\n",
    "    x_in = Input(shape=image_shape)\n",
    "    c_in = Input(shape=(image_shape[0], image_shape[1], c_dim))\n",
    "    \n",
    "    z = Input(shape=noise_dim)\n",
    "    \n",
    "    lambda_z = adative_noise_multiplier(z)\n",
    "    x = tf.concat([x_in, lambda_z * z], axis=-1)\n",
    "    # in the past, c_in is of shape (c_dim,), now c_in has also the spacial information, therefore no need to tf.tile(c_in, [1, x_in.shape[1], x_in.shape[2], 1])   \n",
    "    x = conv(x, channel, kernel_size=7, strides=1, pad=3, use_bias=False)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "\n",
    "    # Down-Sampling\n",
    "    for i in range(3):\n",
    "      x = conv(x, channel*2, kernel_size=4, strides=2, pad=1, use_bias=False)\n",
    "      x = InstanceNormalization()(x)\n",
    "      x = ReLU()(x)\n",
    "\n",
    "      channel = channel * 2\n",
    "\n",
    "    # Bottleneck\n",
    "    for i in range(n_res):\n",
    "      x = res_block(x, channel, use_bias=False)\n",
    "\n",
    "    # Up-Sampling\n",
    "    for i in range(3):\n",
    "      # need to feed the spatial control map here\n",
    "      x = deconv(x, channel//2, kernel_size=4, strides=2, use_bias=False)\n",
    "      # spade normalization instead\n",
    "      x = spade_resblock(c_in, x, channel//2)\n",
    "      x = ReLU()(x)\n",
    "\n",
    "      channel = channel // 2\n",
    "    \n",
    "    \n",
    "    pre_mask = conv(x, filters=1, kernel_size=7, strides=1, pad=3, use_bias=False)\n",
    "    mask = Activation(\"sigmoid\")(pre_mask)\n",
    "    \n",
    "    defect_overlay = conv(x, filters=3, kernel_size=7, strides=1, pad=3, use_bias=False)\n",
    "    defect_overlay = tf.reshape(defect_overlay, (2352, 8, 8, 1))\n",
    "    defect_overlay = tf.einsum(\"oik...,okj...->oij...\", tf.einsum(\"oikb,okjb->oijb\", DCT_U_T, defect_overlay), DCT_U)\n",
    "    defect_overlay = tf.einsum(\"oij...,oij...->oij...\", DCT_freq_domain_mask, defect_overlay)\n",
    "    defect_overlay = tf.einsum(\"oik...,okj...->oij...\", tf.einsum(\"oik...,okj...->oij...\", DCT_U, defect_overlay), DCT_U_T)\n",
    "    defect_overlay = tf.reshape(defect_overlay, (224,224,3))\n",
    "    defect_overlay = Activation(\"tanh\")(defect_overlay)\n",
    "    model = Model([x_in, c_in, z], [defect_overlay, mask])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6ec2580-351c-48f6-a7ea-fb4fddf3e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ebd232-1359-4c64-80cb-095162dc903e",
   "metadata": {},
   "source": [
    "# Dataset Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "415824f7-fb26-40ab-89d2-4dcb2b523f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "043de96a-4946-4847-b93c-09e9f4214464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(index, length):\n",
    "  zeros = np.zeros((length, ))\n",
    "  zeros[index] = 1\n",
    "  return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eaddb0c-1be5-42a0-b9c2-dd301494cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_and_spatialCatMap_and_defectOneHot_and_normalOnehot(segment_filepath, index):  \n",
    "  # only EagerTensor can be decoded as follows:\n",
    "  index = int(bytes.decode(index))\n",
    "  segment_filepath = bytes.decode(segment_filepath)\n",
    "  segment = img_to_array(load_img(segment_filepath, target_size=(SIZE,SIZE), color_mode=\"grayscale\"))\n",
    "  segment = np.where(segment>0.5, 1, 0)\n",
    "  \n",
    "  spatial_cat_map = np.zeros((SIZE, SIZE, c_dim))\n",
    "  \n",
    "  # create spatial_categorical map from segmentation and index of the defect class\n",
    "  \n",
    "  for x in range(SIZE):\n",
    "    for y in range(SIZE):\n",
    "      if segment[x,y,0] > 0:\n",
    "        spatial_cat_map[x,y,index] = 1\n",
    "  \n",
    "  defect_onehot = one_hot(index, c_dim)\n",
    "  normal_onehot = one_hot(c_dim-1, c_dim) # onehot with last entry as 1, else 0\n",
    "      \n",
    "  return tf.convert_to_tensor(segment, dtype=tf.float32), \\\n",
    "          tf.convert_to_tensor(spatial_cat_map, dtype=tf.float32), \\\n",
    "          tf.convert_to_tensor(defect_onehot, dtype=tf.float32),\\\n",
    "          tf.convert_to_tensor(normal_onehot, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc2c126f-9dc2-4823-b81c-b7e621e0d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def path_to_img(zipped_filepaths):\n",
    "  normal_filepath = zipped_filepaths[0]\n",
    "  defect_filepath = zipped_filepaths[1]\n",
    "  segment_filepath = zipped_filepaths[2]\n",
    "  defect_index = zipped_filepaths[3]\n",
    "  \n",
    "  normal = tf.io.read_file(normal_filepath)\n",
    "  normal = tf.image.decode_png(normal, channels=3)\n",
    "  normal = tf.image.resize(normal, (SIZE, SIZE))\n",
    "  normal = (normal/127.5) - 1\n",
    "  \n",
    "  \n",
    "  defect = tf.io.read_file(defect_filepath)\n",
    "  defect = tf.image.decode_png(defect, channels=3)\n",
    "  defect = tf.image.resize(defect, (SIZE, SIZE))\n",
    "  defect = (defect/127.5) - 1\n",
    "  \n",
    "  \n",
    "  segment, spatial_cat_map, defect_onehot, normal_onehot = tf.numpy_function(\n",
    "                                                 func=get_segment_and_spatialCatMap_and_defectOneHot_and_normalOnehot, \n",
    "                                                 inp=[segment_filepath, defect_index], \n",
    "                                                 Tout = [tf.float32, tf.float32, tf.float32, tf.float32]\n",
    "                                                )\n",
    "      \n",
    "  return (normal, defect, segment, defect_index, spatial_cat_map, defect_onehot, normal_onehot)\n",
    "\n",
    "def get_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen(random_segmentations=False):\n",
    "  normals = []\n",
    "  defects = []\n",
    "  defect_segmentations = []\n",
    "  defect_indexes = []\n",
    "\n",
    "  for label in labels:\n",
    "    index = labels.index(label)\n",
    "    normals += glob.glob(f\"{dataset_dir}/{label}/normal/*.jpg\")\n",
    "    defects += glob.glob(f\"{dataset_dir}/{label}/defect/*.jpg\")\n",
    "    defect_segmentations += glob.glob(f\"{dataset_dir}/{label}/defect_segmentation/*.png\")\n",
    "    \n",
    "    if random_segmentations:\n",
    "      random.shuffle(defect_segmentations)\n",
    "      \n",
    "    defect_indexes += [str(index)] * len(normals) # normals, defects, defect_segementations are all of the same length, just use one of them\n",
    "    \n",
    "  normal_defect_defectSeg = list(zip(normals, defects, defect_segmentations, defect_indexes))\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(normal_defect_defectSeg)\\\n",
    "              .map(path_to_img)\\\n",
    "              .batch(batch_size)\\\n",
    "              .shuffle(buffer_size)\\\n",
    "              .cache()\n",
    "\n",
    "  return iter(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26bd80bf-fd6f-49d5-acdc-da4739f3f701",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15644\\676474440.py:4 path_to_img  *\n        normal_filepath = zipped_filepaths[0]\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1036 _slice_helper\n        return strided_slice(\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1209 strided_slice\n        op = gen_array_ops.strided_slice(\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10473 strided_slice\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3528 _create_op_internal\n        ret = Operation(\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Index out of range using input dim 0; input has only 0 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](args_0, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [], [1], [1], [1] and with computed input tensors: input[3] = <1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     22\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(spatial_cat_map[:,:,index])\n\u001b[1;32m---> 24\u001b[0m \u001b[43mview_dataset_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mview_dataset_sample\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mview_dataset_sample\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m   normals, defects, segments, indexes, spatial_cat_maps, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mget_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;66;03m#   spatial_cat_map_[:,:,index] = segments\u001b[39;00m\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m):\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mget_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen\u001b[1;34m(random_segmentations)\u001b[0m\n\u001b[0;32m     44\u001b[0m   defect_indexes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(index)] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(normals) \u001b[38;5;66;03m# normals, defects, defect_segementations are all of the same length, just use one of them\u001b[39;00m\n\u001b[0;32m     46\u001b[0m normal_defect_defectSeg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(normals, defects, defect_segmentations, defect_indexes))\n\u001b[1;32m---> 47\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_defect_defectSeg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_img\u001b[49m\u001b[43m)\u001b[49m\\\n\u001b[0;32m     49\u001b[0m             \u001b[38;5;241m.\u001b[39mbatch(batch_size)\\\n\u001b[0;32m     50\u001b[0m             \u001b[38;5;241m.\u001b[39mshuffle(buffer_size)\\\n\u001b[0;32m     51\u001b[0m             \u001b[38;5;241m.\u001b[39mcache()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(dataset)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1805\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;124;03m\"\"\"Maps `map_func` across the elements of this dataset.\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m \n\u001b[0;32m   1670\u001b[0m \u001b[38;5;124;03mThis transformation applies `map_func` to each element of this dataset, and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;124;03m  Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_parallel_calls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1805\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1807\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[0;32m   1808\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1809\u001b[0m       map_func,\n\u001b[0;32m   1810\u001b[0m       num_parallel_calls,\n\u001b[0;32m   1811\u001b[0m       deterministic,\n\u001b[0;32m   1812\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4203\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   4201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m   4202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[1;32m-> 4203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4207\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4208\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[0;32m   4209\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   4210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4213\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m   4214\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_structure)\n\u001b[0;32m   4215\u001b[0m \u001b[38;5;28msuper\u001b[39m(MapDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3525\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3522\u001b[0m resource_tracker \u001b[38;5;241m=\u001b[39m tracking\u001b[38;5;241m.\u001b[39mResourceTracker()\n\u001b[0;32m   3523\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracking\u001b[38;5;241m.\u001b[39mresource_tracker_scope(resource_tracker):\n\u001b[0;32m   3524\u001b[0m   \u001b[38;5;66;03m# TODO(b/141462134): Switch to using garbage collection.\u001b[39;00m\n\u001b[1;32m-> 3525\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3526\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m add_to_graph:\n\u001b[0;32m   3527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function\u001b[38;5;241m.\u001b[39madd_to_graph(ops\u001b[38;5;241m.\u001b[39mget_default_graph())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3051\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3044\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3045\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   3046\u001b[0m \n\u001b[0;32m   3047\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;124;03m    *args: inputs to specialize on.\u001b[39;00m\n\u001b[0;32m   3049\u001b[0m \u001b[38;5;124;03m    **kwargs: inputs to specialize on.\u001b[39;00m\n\u001b[0;32m   3050\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3051\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3052\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3053\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3054\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3019\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3017\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3018\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3019\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3020\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   3021\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   3022\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3193\u001b[0m ]\n\u001b[0;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3518\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3512\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m   3513\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m   3514\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m   3515\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   3516\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m   3517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m-> 3518\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43m_wrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3519\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m   3520\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3453\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>._wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack_args(nested_args):\n\u001b[0;32m   3451\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m-> 3453\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3454\u001b[0m \u001b[38;5;66;03m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[39;00m\n\u001b[0;32m   3455\u001b[0m \u001b[38;5;66;03m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[39;00m\n\u001b[0;32m   3456\u001b[0m \u001b[38;5;66;03m# those tensors into a single tensor, because the customized\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3462\u001b[0m \u001b[38;5;66;03m# the return value into a single tensor can use an explicit\u001b[39;00m\n\u001b[0;32m   3463\u001b[0m \u001b[38;5;66;03m# `tf.stack()` before returning.\u001b[39;00m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:670\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    669\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    671\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15644\\676474440.py:4 path_to_img  *\n        normal_filepath = zipped_filepaths[0]\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1036 _slice_helper\n        return strided_slice(\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1209 strided_slice\n        op = gen_array_ops.strided_slice(\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10473 strided_slice\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3528 _create_op_internal\n        ret = Operation(\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\user\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Index out of range using input dim 0; input has only 0 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](args_0, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [], [1], [1], [1] and with computed input tensors: input[3] = <1>.\n"
     ]
    }
   ],
   "source": [
    "def view_dataset_sample():\n",
    "  normals, defects, segments, indexes, spatial_cat_maps, _, _ = next(get_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen())\n",
    "  #   spatial_cat_map_[:,:,index] = segments\n",
    "  for i in range(0, 1):\n",
    "    normal = normals[i].numpy().astype(\"float32\")\n",
    "    defect = defects[i].numpy().astype(\"float32\")\n",
    "    segment = segments[i].numpy().astype(\"float32\")\n",
    "    spatial_cat_map = spatial_cat_maps[i]\n",
    "    index = int(indexes[i])\n",
    "    label = labels[index]\n",
    "    \n",
    "    print(\"label\", label)\n",
    "    plt.figure(figsize=(6, 15))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(((normal+1)*127.5).astype(\"uint8\"))\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(((defect+1)*127.5).astype(\"uint8\"))\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(spatial_cat_map[:,:,index])\n",
    "    \n",
    "view_dataset_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe580c-419d-42e0-85d9-535ba44020a1",
   "metadata": {},
   "source": [
    "# Train Loop with Helper Function to see Intermediate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f8489-5c38-4c8f-bb10-db93b8c1ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = MeanAbsoluteError()\n",
    "cce = CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a56e5b18-462f-4e5d-8bba-40a23fa7aed5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m()\n\u001b[0;32m      2\u001b[0m disc \u001b[38;5;241m=\u001b[39m discriminator()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "gen = generator()\n",
    "disc = discriminator()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e8707-77c5-4ab5-b7f4-0a41fc614b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def view_generator_sample(image_name=None, show_in_notebook=True):\n",
    "  datagen = get_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen()\n",
    "  dategen_randomSeg = get_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen(random_segmentations=True)\n",
    "\n",
    "  normals, defects, segments, indexes, spatial_cat_maps, _, _ = next(datagen)\n",
    "  normals_, defects_, segments_, indexes_, spatial_cat_maps_, _, _ = next(dategen_randomSeg)\n",
    "  #   spatial_cat_map_[:,:,index] = segments\n",
    "  \n",
    "  if image_name is not None:\n",
    "    print(\"\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"---------\")\n",
    "    print(image_name)\n",
    "  \n",
    "  plt.figure(figsize=(17, 10))\n",
    "  \n",
    "  for i in range(0, 1):\n",
    "    spatial_cat_map_randomSeg = spatial_cat_maps_[i]\n",
    "    \n",
    "    spatial_cat_map = spatial_cat_maps[i]\n",
    "    normal = normals[i].numpy().astype(\"float32\")\n",
    "    \n",
    "    defect = defects[i].numpy().astype(\"float32\")\n",
    "    \n",
    "    for row_count, (from_, spa_cat, description) in enumerate([\n",
    "      (defect, spatial_cat_map, \"from_defect\"), \n",
    "      (normal, spatial_cat_map, \"from_normal\"), \n",
    "      (normal, spatial_cat_map_randomSeg, \"from_random_segment\")\n",
    "    ]):\n",
    "      segment = segments[i].numpy().astype(\"float32\")\n",
    "      z = np.random.normal(0, 1, (1, )+noise_dim)\n",
    "\n",
    "      top, m = gen.predict([from_[np.newaxis,...], spa_cat[np.newaxis,...], z])\n",
    "      top_layer = np.squeeze(top)\n",
    "\n",
    "\n",
    "      index = int(indexes[i])\n",
    "      label = labels[index]\n",
    "\n",
    "\n",
    "\n",
    "      plt.subplot(3, 5, 5*row_count + 1)\n",
    "      plt.imshow(((from_+1)*127.5).astype(\"uint8\"))\n",
    "\n",
    "      plt.subplot(3, 5, 5*row_count + 2)\n",
    "      plt.imshow(spa_cat[:,:,index])\n",
    "\n",
    "\n",
    "      plt.subplot(3, 5, 5*row_count + 3)\n",
    "\n",
    "      plt.imshow(((top_layer+1)*127.5).astype(\"uint8\"))\n",
    "\n",
    "      plt.subplot(3, 5, 5*row_count + 4)\n",
    "      print(\"max mask value inside mask:\", np.amax(m))\n",
    "      plt.imshow(np.squeeze(m))\n",
    "\n",
    "      plt.subplot(3, 5, 5*row_count + 5)\n",
    "      gened_defects = from_ * (1-m)  + top_layer * m\n",
    "      plt.imshow(((gened_defects[0]+1)*127.5).astype(\"uint8\"))\n",
    "\n",
    "\n",
    "    if image_name is not None:\n",
    "      plt.savefig(f\"{image_name}\", dpi=80, bbox_inches=\"tight\")\n",
    "\n",
    "    if show_in_notebook:\n",
    "      plt.show()\n",
    "  \n",
    "view_generator_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62016b31-da3c-45d2-8e3e-98e4aaa2b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penality(critic, real_sample, fake_sample):\n",
    "    epsilon = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    interpolated = epsilon * real_sample + (1 - epsilon) * fake_sample\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "      gp_tape.watch(interpolated)\n",
    "      critic_inter = critic(interpolated, training=True)\n",
    "\n",
    "    grads = gp_tape.gradient(critic_inter, [interpolated])[0]\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    penality = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return penality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e45293-a8b7-4f2d-8b12-93166994928b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoches=10, sample_per_batch=15, show_in_notebook=True):\n",
    "  \n",
    "  g_opt = Adam(lr=lr, beta_1=0, beta_2=0.9)\n",
    "  d_opt = Adam(lr=lr, beta_1=0, beta_2=0.9)\n",
    "  \n",
    "  \n",
    "  for epoch in range(epoches):\n",
    "    batch = 0\n",
    "    dataset_gen = get_normal_defect_defectSegment_defectIndex_spatialCat_defectOneHot_normalOnehot_gen()\n",
    "    \n",
    "    if epoch >= 0 and epoch <= 2:\n",
    "      lambda_mask = 5.0\n",
    "    elif  epoch >= 3 and epoch <= 5:\n",
    "      lambda_mask = 0.5\n",
    "    else:\n",
    "      lambda_mask = 0\n",
    "    \n",
    "    \n",
    "    for normals, defects, _, _, spatial_cat_maps, defect_onehots, normal_onehots in dataset_gen:\n",
    "      batch += 1\n",
    "      print(\"epoch\", epoch+1, \"batch\", batch, \"lambda_mask\", lambda_mask, end=\"\\r\")\n",
    "      \n",
    "      for iteration in range(n_disc_iteration):\n",
    "        update_gen = (iteration+1)%n_disc_iteration == 0\n",
    "\n",
    "        for from_, to_, from_onehots, target_onehots in [(normals, defects, normal_onehots, defect_onehots), (defects, normals, defect_onehots, normal_onehots)]:\n",
    "          z_1 = tf.random.normal((1,)+noise_dim, 0, 1)\n",
    "          z_2 = tf.random.normal((1,)+noise_dim, 0, 1)\n",
    "\n",
    "          with tf.GradientTape(persistent=True) as tape:\n",
    "            # naming convetion is from normal --> defect. Roles of normal and defect can be interchanged\n",
    "            defect_overlays, n2d_masks = gen([from_, spatial_cat_maps, z_1], training=True)\n",
    "            gened_defects = from_ * (1-n2d_masks)  + defect_overlays * n2d_masks\n",
    "\n",
    "            restore_overlays, d2n_masks = gen([gened_defects, spatial_cat_maps, z_2], training=True)\n",
    "            restoration = gened_defects * (1-d2n_masks) + restore_overlays * d2n_masks\n",
    "\n",
    "            d_logit_on_gened, d_cls_on_gened = disc(gened_defects, training=True)\n",
    "            d_logit_on_real, d_cls_on_real = disc(from_, training=True)\n",
    "\n",
    "            cls_loss_on_gened = cce(target_onehots, d_cls_on_gened)\n",
    "            cls_loss_on_real = cce(from_onehots, d_cls_on_real)\n",
    "\n",
    "            gp = gradient_penality(disc, from_, gened_defects)\n",
    "\n",
    "            d_wgan_gp_loss = tf.math.reduce_mean(d_logit_on_gened) - tf.reduce_mean(d_logit_on_real) + 10 * gp\n",
    "\n",
    "\n",
    "            g_cycle_loss = mae(from_, restoration)\n",
    "\n",
    "            g_mask_cycle_loss = mae(n2d_masks, d2n_masks)\n",
    "\n",
    "            g_mask_vanishing_loss = -tf.math.log(tf.math.reduce_mean(mae(n2d_masks, 0.0) +  mae(d2n_masks, 0.0))) \n",
    "            g_mask_spatial_constraint_loss = tf.math.reduce_mean(mae(n2d_masks, 0.0) +  mae(d2n_masks, 0.0))\n",
    "\n",
    "            g_wgan_gp_loss = - tf.math.reduce_mean(d_logit_on_gened)\n",
    "\n",
    "            d_loss = tf.tensordot(\n",
    "              [1,              5.0             ],\n",
    "              [d_wgan_gp_loss, cls_loss_on_real],\n",
    "              axes = 1\n",
    "            )\n",
    "\n",
    "            if update_gen:\n",
    "              g_loss = tf.tensordot(\n",
    "                [10.0,         5.0,               lambda_mask,           5.0,                            10.0,              1.0           ],\n",
    "                [g_cycle_loss, g_mask_cycle_loss, g_mask_vanishing_loss, g_mask_spatial_constraint_loss, cls_loss_on_gened, g_wgan_gp_loss],\n",
    "                axes = 1\n",
    "              )\n",
    "              \n",
    "          grad_of_d = tape.gradient(d_loss, disc.trainable_variables)\n",
    "          d_opt.apply_gradients(zip(grad_of_d, disc.trainable_variables))\n",
    "\n",
    "          if update_gen:\n",
    "            grad_of_g = tape.gradient(g_loss, gen.trainable_variables)\n",
    "            g_opt.apply_gradients(zip(grad_of_g, gen.trainable_variables))\n",
    "\n",
    "      \n",
    "      if (batch % sample_per_batch) == 0:\n",
    "        view_generator_sample(\n",
    "          image_name=\"epoch-{}-batch-{}-224-DCT-ver\".format(\n",
    "            str(epoch+1).zfill(3), \n",
    "            str(batch).zfill(5)\n",
    "          ),\n",
    "          show_in_notebook=show_in_notebook\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec128d-f5da-4e80-a27a-f4de94d79c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epoches=8, sample_per_batch=15, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac715168-ed50-4337-84ff-14731d2b00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen.save_weights(\"./defect-gan-224ver-DCT-01_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859f2a96-dad7-4ec4-9e9d-83e9eded07e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c303aec1-f16e-4b07-848c-962c18a1a65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dc97e19-71ef-4345-b9b3-4e4aa34b3cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-23 10:11:14\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "local_time = re.sub(r\"\\..*$\", \"\",  str(datetime.today()))\n",
    "print(local_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e15f65-b218-463c-9f75-623f24520038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 5, 23, 10, 7, 16, 125925)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa3b948-8ab5-4e15-81bc-f7d31710dfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39a1046-d01b-4e0d-b75f-0cfa882f5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e06317c4-cfe2-4fae-9bb4-b5bdeb210371",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(input_shape=(512,512,3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99afa777-7f2b-4cfc-acf6-4b62b1a1b901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 512, 512, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f31bcb0f-c9af-4568-8ed9-6d7e78dbc447",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg = Model(vgg.input, vgg.layers[17].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fceb360-e5c7-46a0-bf2d-4a85ec4421f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 512, 512, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4f0f37c-cbe4-4a91-828d-b5d33da2fb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224/56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0bc8c-f9f8-4959-bd22-71cf83786537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
